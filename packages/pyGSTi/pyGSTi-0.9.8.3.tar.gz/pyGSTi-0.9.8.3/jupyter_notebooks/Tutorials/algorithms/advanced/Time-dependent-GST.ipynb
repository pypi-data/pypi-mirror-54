{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-dependent models and gate set tomography\n",
    "This tutorial demonstrates how time dependence can be added to models in pyGSTi and, since gate set tomography (GST) just optimizes model parameters, how to run time-dependent GST.  \n",
    "\n",
    "<font style=\"color:red\">**Notice: this topic describes \"beta level\" functionality in pyGSTi!**  It may contain bugs and holes in its implementation, which will be addressed in future releases.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsti\n",
    "from pygsti.construction import std1Q_XYI\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependent models\n",
    "To make a time-dependent `Model`, you create a time dependent gate or operation and add this to any of the models in pyGSTi.  (**Expert note**: this isn't quite true - currently, only models with `sim_type=\"map\"` support time-dependent evaluation of circuit outcomes, so we're currently limited to using this simulation type.)  Here's an example of how to make a custom idle operation that depolarizes its input state more and more over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTimeDependentIdle(pygsti.obj.DenseOperator):\n",
    "    \"\"\"And idle that depolarizes over time with a parameterized rate\"\"\"\n",
    "    def __init__(self, initial_depol_rate):\n",
    "        #initialize with no noise\n",
    "        self.from_vector([initial_depol_rate]) \n",
    "        self.set_time(0.0)\n",
    "        super(MyTimeDependentIdle,self).__init__(self.base, \"densitymx\") # this is *super*-operator, so \"densitymx\"\n",
    "        \n",
    "    def num_params(self): \n",
    "        return 1 # we have two parameters\n",
    "    \n",
    "    def to_vector(self):\n",
    "        return np.array([self.depol_rate],'d') #our parameter vector\n",
    "        \n",
    "    def from_vector(self,v):\n",
    "        #initialize from parameter vector v\n",
    "        self.depol_rate = v[0]\n",
    "        \n",
    "    def set_time(self,t):\n",
    "        a = 1.0-min(self.depol_rate*t,1.0)\n",
    "        \n",
    "        # .base is a member of DenseOperator and is a numpy array that is \n",
    "        # the dense Pauli transfer matrix of this operator\n",
    "        self.base = np.array([[1,   0,   0,   0],\n",
    "                              [0,   a,   0,   0],\n",
    "                              [0,   0,   a,   0],\n",
    "                              [0,   0,   0,   a]],'d')\n",
    "        \n",
    "    def transform(self, S):\n",
    "        # Update self with inverse(S) * self * S (used in gauge optimization)\n",
    "        raise NotImplementedError(\"MyTimeDependentIdle cannot be transformed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key piece to note in the above class is the `set_time` method, which will be called sometime after `from_vector` and takes over responsiblility (from `from_vector`) for setting the object's `.base` member to the process matrix based on the parameters (in `from_vector`'s `v` *and* the time given to `set_time`). \n",
    "\n",
    "Here's an example of how to see what a `MyTimeDependentIdle(1.0)` gate looks like at the time 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0. ]\n",
      " [0.  0.9 0.  0. ]\n",
      " [0.  0.  0.9 0. ]\n",
      " [0.  0.  0.  0.9]]\n"
     ]
    }
   ],
   "source": [
    "t = 0.1\n",
    "Gi_at_t = MyTimeDependentIdle(1.0)\n",
    "Gi_at_t.set_time(t)\n",
    "Gi_matrix_at_t = Gi_at_t.todense()\n",
    "print(Gi_matrix_at_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a `MyTimeDependentIdle` gate to a model just like any other operator (in pyGSTi all operators are considered potentially time-dependent, and so the base class of our idle gate is `DenseOperator` just as it would be if we were creating a custom time-independent gate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = std1Q_XYI.target_model(sim_type=\"map\")\n",
    "mdl['Gi'] = MyTimeDependentIdle(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it - `mdl` is a time-dependent model, where `Gi` depolarizes with strength equal to the current time.  To compute the probability of a circuit, *GiGi* for example, we just call the usual `probs` function but specify a `time` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.9050000000000002), (('1',), 0.09499999999999997)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.probs( ('Gi','Gi'), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero probability is equal to `0.5 * (1 + 0.9**2) = 0.905`, where the `0.9` comes from the Gi gate depolarization rate of 0.1 at time 0.1.  Note that this is the same as what you'd get using the `Gi_matrix_at_t` above (since our \"t\" was 0.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.905]]\n"
     ]
    }
   ],
   "source": [
    "E = mdl['Mdefault']['0']\n",
    "rho = mdl['rho0']\n",
    "print(np.dot(E.T, np.dot(Gi_matrix_at_t, np.dot(Gi_matrix_at_t, rho))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-dependent (or \"time aware\") circuits\n",
    "`Circuit` objects may include time information: labels within a circuit (e.g. `\"Gi\"`) may contain a *relative* time giving the duration of the operation being labeled.  By default, all labels have zero duration, meaning all the operations within the circuit are interpreted as occurring at the same time.  The below example gives the `Gi` gate a duration of 0.1, so that in the circuit simulation the first `Gi` occurs at time 0.1 and the second at 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.8600000000000002), (('1',), 0.14)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gi_with_duration = pygsti.obj.Label('Gi',time=0.1)\n",
    "mdl.probs( (Gi_with_duration,Gi_with_duration), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86]]\n"
     ]
    }
   ],
   "source": [
    "Gi_at_t.set_time(0.1)\n",
    "Gi_matrix_at_t1 = Gi_at_t.todense()\n",
    "Gi_at_t.set_time(0.2)\n",
    "Gi_matrix_at_t2 = Gi_at_t.todense()\n",
    "print(np.dot(E.T, np.dot(Gi_matrix_at_t2, np.dot(Gi_matrix_at_t1, rho))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following \"!\"-shorthand (exclamation point followed by time) notation to specify label durations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.8600000000000002), (('1',), 0.14)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.probs( (('Gi','!0.1'),('Gi','!0.1')), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependent data\n",
    "When `DataSet` objects contain timestamped data, these timestamps indicate at what *absolute* time the relevant circuit began executing when it produced certain data.  These time values correspond to those given to the `time` argument of `probs` above.\n",
    "\n",
    "At first, we don't bother with \"time-aware\" circuits, and just create a list of two sample circuits.  We then use the `times` argument of `generate_fake_data` to construct a `DataSet` with 100 samples of data taken at each of three times: 0, 0.1, and 0.2 (arbitrary time units).  By setting `sampleError=\"none\"` we can see the underlying outcome probabilities in the data (and how the depolarization caused by `Gi` increases with time): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset outcomes: OrderedDict([(('0',), 0), (('1',), 1)])\n",
      "Gi :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.   0.  95.   5.  90.  10.]\n",
      "\n",
      "GiGi :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.    0.   90.5   9.5  82.   18. ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits = pygsti.construction.circuit_list([ ('Gi',), ('Gi','Gi')]) # just pick some circuits\n",
    "\n",
    "ds = pygsti.construction.generate_fake_data(mdl, circuits, nSamples=100,\n",
    "                                            sampleError='none', seed=1234, times=[0,0.1,0.2])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataSet` with timestamps displays 3 parallel arrays for each circuit: \"Outcome Label Indices\", \"Time stamps\", and \"Repetitions\".  Each index corresponds to a bin of some number (given by \"Repetitions\") of X-outcomes (X given by \"Outcome Label Indices\") occuring at some time (given by \"Time stamps\").  We see that for each of the two circuits there are bins of 0- and 1-outcomes at each of times 0, 0.1, and 0.2.  Summing the bin counts (outcome repetitions) at each time, for a given circuit, gives 100.\n",
    "\n",
    "We can also add a duration of 0.05 time units to each `\"Gi\"` gate.  This makes the depolarization of the length-2 sequence a bit worse because the second application of `\"Gi\"` occurs at a time 0.05 units after the start of the circuit, at which point the noise on the gate as increased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset outcomes: OrderedDict([(('0',), 0), (('1',), 1)])\n",
      "Gi!0.05 :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.   0.  95.   5.  90.  10.]\n",
      "\n",
      "Gi!0.05Gi!0.05 :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [97.5   2.5  88.25 11.75 80.   20.  ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits = pygsti.construction.circuit_list([ (('Gi','!0.05'),), (('Gi','!0.05'),('Gi','!0.05'))])\n",
    "\n",
    "ds = pygsti.construction.generate_fake_data(mdl, circuits, nSamples=100,\n",
    "                                            sampleError='none', seed=1234, times=[0,0.1,0.2])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-dependent gate set tomography (TD-GST)\n",
    "To run gate set tomography, we'll need more sequences than the two in the example above.  We'll generate some timestamped data for the standard set of GST sequences for a 1-qubit $X(\\pi/2)$, $Y(\\pi/2)$, $I$ gate set.  In particular, we create a data-generating model that has a `MyTimeDependentIdle` `\"Gi\"` gate with a depolarization \"acceleration\" rate of 1.0, and we generate 10 counts at each of 10 equally spaced times between 0 and 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_fiducials, meas_fiducials = std1Q_XYI.prepStrs, std1Q_XYI.effectStrs\n",
    "germs = std1Q_XYI.germs\n",
    "maxLengths = [1,2]\n",
    "\n",
    "mdl_datagen = std1Q_XYI.target_model(sim_type=\"map\").depolarize(op_noise=0.01, spam_noise=0.001)\n",
    "mdl_datagen['Gi'] = MyTimeDependentIdle(1.0)\n",
    "listOfExperiments = pygsti.construction.make_lsgst_experiment_list(\n",
    "    mdl_datagen, prep_fiducials, meas_fiducials, germs, maxLengths)\n",
    "\n",
    "#Data for initial non-sparse mode\n",
    "ds = pygsti.construction.generate_fake_data(mdl_datagen, listOfExperiments, nSamples=10,\n",
    "                                            sampleError=\"binomial\", seed=1234, times=np.linspace(0,0.3,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run GST on this timestamped data similar to any other data, using `do_long_sequence_gst`.  The key difference is that the advanced option `\"timeDependent\"` is set to `True`.  This tells `do_long_sequence_gst` to take the timestamps in the given `DataSet` seriously, and perform time-dependent circuit simulations rather than aggregating the counts across all times (the behavior when the default, `\"timeDependent\": False`, is used).\n",
    "\n",
    "Running time-dependent GST with 10 timesteps requires 10 times the number of circuit simulations (each circuit needs to be simulated 10 times).  This, coupled with the fact that this the time-dependent simulation routines are less optimized in pyGSTi, means this running time-dependent GST is significantly slower than normal GST.  Note also that we set `gaugeOptParams=False`.  This disables gauge optimization, and this is necessary since it won't work because our `MyTimeDependentIdle` operation doesn't implement `transform` (the action of a gauge transformation).\n",
    "\n",
    "The cell below will take around 5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Circuit Creation ---\n",
      "   168 sequences created\n",
      "   Dataset has 168 entries: 168 utilized, 0 requested sequences were missing\n",
      "--- Iterative MLGST: Iter 1 of 2  92 operation sequences ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "    bulk_evaltree: created initial tree (92 strs) in 0s\n",
      "    bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "    Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "     groups of ~1 procs each, to distribute over 32 params (taken as 1 param groups of ~32 params).\n",
      "    --- Outer Iter 0: norm_f = 1.40765e+06, mu=0, |J|=34737.8\n",
      "    --- Outer Iter 1: norm_f = 786.28, mu=51712.6, |J|=1922.44\n",
      "    --- Outer Iter 2: norm_f = 753.095, mu=17237.5, |J|=1859.86\n",
      "    --- Outer Iter 3: norm_f = 734.152, mu=5745.84, |J|=1883.63\n",
      "    --- Outer Iter 4: norm_f = 715.388, mu=1915.28, |J|=1905.99\n",
      "    --- Outer Iter 5: norm_f = 693.495, mu=638.427, |J|=1956.58\n",
      "    --- Outer Iter 6: norm_f = 670.049, mu=212.809, |J|=4359.44\n",
      "    --- Outer Iter 7: norm_f = 658.828, mu=70.9363, |J|=4374.04\n",
      "    --- Outer Iter 8: norm_f = 656.759, mu=23.6454, |J|=4395.9\n",
      "    --- Outer Iter 9: norm_f = 656.505, mu=7.88181, |J|=4413.2\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 0.0001\n",
      "  Sum of Chi^2 = 656.505 (920 data params - 22 model params = expected mean of 898; p-value = 1)\n",
      "  Completed in 138.3s\n",
      "  2*Delta(log(L)) = 128.33\n",
      "  Iteration 1 took 138.3s\n",
      "  \n",
      "--- Iterative MLGST: Iter 2 of 2  168 operation sequences ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "    bulk_evaltree: created initial tree (168 strs) in 0s\n",
      "    bulk_evaltree: split tree (1 subtrees) in 0s\n",
      "    Created evaluation tree with 1 subtrees.  Will divide 1 procs into 1 (subtree-processing)\n",
      "     groups of ~1 procs each, to distribute over 32 params (taken as 1 param groups of ~32 params).\n",
      "    --- Outer Iter 0: norm_f = 6008.06, mu=0, |J|=122913\n",
      "    --- Outer Iter 1: norm_f = 3136.75, mu=2.76628e+06, |J|=25234.4\n",
      "    --- Outer Iter 2: norm_f = 2156.12, mu=2.55555e+06, |J|=7218.54\n",
      "    --- Outer Iter 3: norm_f = 1804.98, mu=2.20016e+06, |J|=3393.46\n",
      "    --- Outer Iter 4: norm_f = 1711.3, mu=1.40264e+06, |J|=2769.34\n",
      "    --- Outer Iter 5: norm_f = 1665.13, mu=467548, |J|=2722.45\n",
      "    --- Outer Iter 6: norm_f = 1603.21, mu=155849, |J|=2739.25\n",
      "    --- Outer Iter 7: norm_f = 1530.87, mu=51949.7, |J|=2761.46\n",
      "    --- Outer Iter 8: norm_f = 1475.68, mu=17316.6, |J|=2790.95\n",
      "    --- Outer Iter 9: norm_f = 1445.09, mu=5772.19, |J|=2788.48\n",
      "    --- Outer Iter 10: norm_f = 1434.24, mu=1924.06, |J|=2764.08\n",
      "    --- Outer Iter 11: norm_f = 1430.71, mu=641.355, |J|=2736.11\n",
      "    --- Outer Iter 12: norm_f = 1427.94, mu=213.785, |J|=2716.22\n",
      "    --- Outer Iter 13: norm_f = 1426.72, mu=71.2617, |J|=2709.69\n",
      "    --- Outer Iter 14: norm_f = 1426.55, mu=23.7539, |J|=2711.97\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 0.0001\n",
      "  Sum of Chi^2 = 1426.55 (1680 data params - 22 model params = expected mean of 1658; p-value = 0.999987)\n",
      "  Completed in 265.8s\n",
      "  2*Delta(log(L)) = 303.858\n",
      "  Iteration 2 took 265.9s\n",
      "  \n",
      "  Switching to ML objective (last iteration)\n",
      "  --- MLGST ---\n",
      "    --- Outer Iter 0: norm_f = 869.568, mu=0, |J|=215.3\n",
      "    --- Outer Iter 1: norm_f = 869.037, mu=225067, |J|=230.34\n",
      "    --- Outer Iter 2: norm_f = 868.85, mu=199759, |J|=248.362\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 0.0001\n",
      "    Maximum log(L) = 868.85 below upper bound of -25667.9\n",
      "      2*Delta(log(L)) = 1737.7 (1680 data params - 22 model params = expected mean of 1658; p-value = 0.0847219)\n",
      "    Completed in 54.6s\n",
      "  2*Delta(log(L)) = 1737.7\n",
      "  Final MLGST took 54.6s\n",
      "  \n",
      "Iterative MLGST Total Time: 458.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: MLGST failed to improve logl: retaining chi2-objective estimate\n"
     ]
    }
   ],
   "source": [
    "target_model = std1Q_XYI.target_model(\"TP\", sim_type=\"map\") # TP-constraints on the non-Gi gates\n",
    "target_model['Gi'] = MyTimeDependentIdle(0.0)\n",
    "target_model.set_simtype('map', max_cache_size=0)\n",
    "\n",
    "results = pygsti.do_long_sequence_gst(ds, target_model, prep_fiducials, meas_fiducials,\n",
    "                                      germs, maxLengths, gaugeOptParams=False, verbosity=3,\n",
    "                                      advancedOptions={'timeDependent': True, # enable time-dependent circuit simulation\n",
    "                                                       'starting point': 'target', # so we don't try to do LGST\n",
    "                                                       'tolerance': 1e-4}) # to speed up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the (non-gauge-optimizeed) best-fit model from `results`, and see what depolarization \"acceleration\" was found.  We find that the value is reasonably close to the value of 1.0 that we used to generate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-dependent idle parameters =  [1.0278963]\n"
     ]
    }
   ],
   "source": [
    "final_mdl = results.estimates['default'].models['final iteration estimate']\n",
    "print(\"Time-dependent idle parameters = \",final_mdl['Gi'].to_vector())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
