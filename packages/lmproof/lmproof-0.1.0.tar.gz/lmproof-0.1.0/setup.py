# -*- coding: utf-8 -*-
from distutils.core import setup

packages = \
['lmproof']

package_data = \
{'': ['*'], 'lmproof': ['resources/*']}

install_requires = \
['lemminflect', 'spacy>=2.0', 'symspellpy', 'torch>=1.2.0', 'transformers']

setup_kwargs = {
    'name': 'lmproof',
    'version': '0.1.0',
    'description': 'Language model powered proof reader for correcting contextual errors in natural language.',
    'long_description': '## lmproof - Language Model Proof Reader\n\nLibrary to do proof-reading corrections for Grammatical Errors, spelling errors, confused word errors and other errors using pre-trained Language Models.\n\nCurrently, we use the language model based approach mentioned in [Christopher Bryant and Ted Briscoe. 2018](http://aclweb.org/anthology/W18-0529) with few changes.\n\nUnlike many approaches to GEC, this approach does NOT require annotated training data and mainly depends on a monolingual language model. The program works by iteratively comparing certain words in a text against alternative candidates and applying a correction if one of these candidates is more probable than the original word. These correction candidates are variously generated by a word inflection library or are otherwise defined manually. Currently, this system only corrects:\n\n    Non-words (e.g. freind and informations)\n    Morphology (e.g. eat, ate, eaten, eating, etc.)\n    Common Determiners and Prepositions (e.g. the, a, in, at, to, etc.)\n    Commonly Confused Words (e.g. bear/bare, lose/loose, etc.)\n\nThis work builds upon https://github.com/chrisjbryant/lmgec-lite/\n\n## Components\n\n### Language Models\n* [pytorch-transformers](https://github.com/huggingface/pytorch-transformers)\n### Inflection generators\n* [LemmInflect](https://github.com/bjascob/LemmInflect) is used to lemmatize and generate inflections for candidate proposals to the language model.\n### Spell Checker\n* [symspellpy](https://github.com/mammothb/symspellpy) is used for obtaining spell check candidates.\n\nThe components are highly modularised to facilitate experimentation with newer scorers and support more languages.\nPre-trained language models for other languages, inflectors, common error patterns can be easily added to support more languages.\n\n## TODOs\n\n* Research on distilling gpt-2 to a smaller model (LSTM?) to reduce the horrendous latency.\n* Experiment on GEC dev sets to obtain optimal thresholds.\n* Anyway to handle insertions.\n* Add more languages.\n* Check whether LemmInflect proposals are actually better than just using [AGID](https://github.com/sai-prasanna/lmgec-lite/tree/master/resources/agid-2016.01.19).',
    'author': 'sai-prasanna',
    'author_email': 'sai.r.prasanna@gmail.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/sai-prasanna/lmproof',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.7',
}


setup(**setup_kwargs)
