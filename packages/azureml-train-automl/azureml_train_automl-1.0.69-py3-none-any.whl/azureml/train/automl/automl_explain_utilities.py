# ---------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# ---------------------------------------------------------
"""Utilities that could be used from AutoML after training for explaining AutoML models."""
from typing import List, Optional, Any, Tuple, Union, cast

import json
import logging

import pandas as pd
import numpy as np
import scipy
from sklearn.externals import joblib
from sklearn.pipeline import make_pipeline, Pipeline

from azureml.automl.core import dataprep_utilities
from azureml.data import TabularDataset
from azureml.core import Run
from automl.client.core.common import constants, logging_utilities
from automl.client.core.common.exceptions import ArgumentException
from azureml.automl.core.console_interface import ConsoleInterface
from automl.client.core.runtime.types import DataInputType, DataSingleColumnInputType
from automl.client.core.runtime.datasets import ClientDatasets
from azureml.automl.core._experiment_observer import ExperimentStatus
from azureml.automl.core.cpu_utilities import _get_num_physical_cpu_cores_model_explanations
from azureml.automl.core.training_utilities import _upgrade_sparse_matrix_type, _is_sparse_matrix_int_type
from azureml.automl.core._vendor.automl.client.core.common.constants import Transformers
from automl.client.core.common.constants import MODEL_PATH
from .exceptions import ConfigException
from .run import AutoMLRun
from ._azure_experiment_observer import AzureExperimentObserver
from azureml.automl.core.automl_base_settings import AutoMLBaseSettings


DefaultWeightRawFeatureToEngineeredFeatureMap = 1.0
AutoMLUIRawFeatureExplanationName = "Raw Feature Explanations"
AutoMLUIEngineeredFeatureExplanationName = "Engineered Feature Explanations"
ModelExplanationRunId = 'model_explain_run_id'


class AutoMLExplainerSetupClass:
    """
    Placeholder class for all objects needed for interface with AzureML explain package.

    :param X_transform: The featurized training features used for fitting pipelines during AutoML experiment.
    :type X_transform: pandas.DataFrame or numpy.ndarray or scipy.sparse.csr_matrix
    :param X_test_raw: The raw test features used evaluating an AutoML trained pipeline.
    :type X_test_raw: pandas.DataFrame or numpy.ndarray or scipy.sparse.csr_matrix
    :param X_test_transform: The featurized test features for evaluating an AutoML estimator.
    :type X_test_transform: pandas.DataFrame or numpy.ndarray or scipy.sparse.csr_matrix
    :param pipeline: The entire fitted AutoML model.
    :type pipeline: sklearn.pipeline
    :param estimator: The AutoML estimator including the model specific preprocessor and learner.
    :type estimator: sklearn.pipeline
    :param featurizer: The AutoML featurizer which does transformations from raw features to engineered features.
    :type featurizer: sklearn.pipeline
    :param engineered_feature_names: The list of names for the features generated by the AutoML featurizers.
    :type engineered_feature_names: List[str]
    :param raw_feature_names: The list of names for the raw features to be explained.
    :type raw_feature_names: List[str]
    :type feature_map: The mapping of which raw features generated which engineered features expressed
                        as a numpy array or scipy sparse matrix.
    :type feature_map: numpy.ndarray or scipy.sparse.csr_matrix
    :param classes: The list of classes discovered in the labeled column in case of classification problem.
    :type raw_feature_names: List[Any]
    """

    def __init__(self, X_transform: Optional[DataInputType] = None,
                 X_test_raw: Optional[DataInputType] = None,
                 X_test_transform: Optional[DataInputType] = None,
                 pipeline: Optional[Pipeline] = None,
                 estimator: Optional[Pipeline] = None,
                 featurizer: Optional[Pipeline] = None,
                 engineered_feature_names: Optional[List[str]] = None,
                 raw_feature_names: Optional[List[str]] = None,
                 feature_map: Optional[DataInputType] = None,
                 classes: Optional[List[Any]] = None):
        """
        Initialize the AutoML explainer setup class.

        :param X_transform: The featurized training features used for fitting pipelines during AutoML experiment.
        :type X_transform: pandas.DataFrame or numpy.ndarray or scipy.sparse.csr_matrix
        :param X_test_raw: The raw test features used evaluating an AutoML trained pipeline.
        :type X_test_raw: pandas.DataFrame or numpy.ndarray or scipy.sparse.csr_matrix
        :param X_test_transform: The featurized test features for evaluating an AutoML estimator.
        :type X_test_transform: pandas.DataFrame or numpy.ndarray or scipy.sparse.csr_matrix
        :param pipeline: The entire fitted AutoML model.
        :type pipeline: sklearn.pipeline
        :param estimator: The AutoML estimator including the model specific preprocessor and learner.
        :type estimator: sklearn.pipeline
        :param featurizer: The AutoML featurizer which does transformations from raw features to engineered features.
        :type featurizer: sklearn.pipeline
        :param engineered_feature_names: The list of names for the features generated by the AutoML featurizers.
        :type engineered_feature_names: List[str]
        :param raw_feature_names: The list of names for the raw features to be explained.
        :type raw_feature_names: List[str]
        :type feature_map: The mapping of which raw features generated which engineered features expressed
                           as a numpy array or scipy sparse matrix.
        :type feature_map: numpy.ndarray or scipy.sparse.csr_matrix
        :param classes: The list of classes discovered in the labeled column in case of classification problem.
        :type raw_feature_names: List[Any]
        """
        self._X_transform = X_transform
        self._X_test_transform = X_test_transform
        self._X_test_raw = X_test_raw
        self._automl_pipeline = pipeline
        self._automl_estimator = estimator
        self._automl_featurizer = featurizer
        self._engineered_feature_names = engineered_feature_names
        self._raw_feature_names = raw_feature_names
        self._feature_map = feature_map
        self._classes = classes

    @property
    def X_transform(self) -> DataInputType:
        """
        Return the featurized training features used for fitting pipelines during AutoML experiment.

        :return: The featurized training features used for fitting pipelines during AutoML experiment.
        :type: DataInputType
        """
        return self._X_transform

    @property
    def X_test_transform(self) -> DataInputType:
        """
        Return the featurized test features for evaluating an AutoML estimator.

        :return: The featurized test features for evaluating an AutoML estimator.
        :type: DataInputType
        """
        return self._X_test_transform

    @property
    def X_test_raw(self) -> DataInputType:
        """
        Return the raw test features used evaluating an AutoML trained pipeline.

        :return: The raw test features used evaluating an AutoML trained pipeline.
        :type: DataInputType
        """
        return self._X_test_raw

    @property
    def automl_pipeline(self) -> Pipeline:
        """
        Return the entire fitted AutoML model.

        :return: The entire fitted AutoML model.
        :type: sklearn.pipeline
        """
        return self._automl_pipeline

    @property
    def automl_estimator(self) -> Pipeline:
        """
        Return the AutoML estimator including the model specific preprocessor and learner.

        :return: The AutoML estimator including the model specific preprocessor and learner.
        :type: sklearn.pipeline
        """
        return self._automl_estimator

    @property
    def automl_featurizer(self) -> Pipeline:
        """
        Return the AutoML featurizer which does transformations from raw features to engineered features.

        :return: The AutoML featurizer which does transformations from raw features to engineered features.
        :type: sklearn.pipeline
        """
        return self._automl_featurizer

    @property
    def engineered_feature_names(self) -> Optional[List[str]]:
        """
        Return the list of names for the features generated by the AutoML featurizers.

        :return: The list of names for the features generated by the AutoML featurizers.
        :type: List[str]
        """
        return self._engineered_feature_names

    @property
    def raw_feature_names(self) -> Optional[List[str]]:
        """
        Return the list of names for the raw features to be explained.

        :return: The list of names for the raw features to be explained.
        :type: List[str]
        """
        return self._raw_feature_names

    @property
    def feature_map(self) -> DataInputType:
        """
        Return the mapping of which raw features generated which engineered features.

        :return: The mapping of which raw features generated which engineered features.
        :type: DataInputType
        """
        return self._feature_map

    @property
    def classes(self) -> Optional[List[Any]]:
        """
        Return the list of classes discovered in the labeled column in case of classification problem.

        :return: The list of classes discovered in the labeled column in case of classification problem.
        :type: List[Any]
        """
        return self._classes

    def __str__(self) -> str:
        """
        Return the string representation on the AutoML explainer setup class.

        :return: The string representation on the AutoML explainer setup class.
        :type: str
        """
        print_str = "The setup class is: \n"
        if self.X_transform is not None:
            print_str += "\tx_train_transform = {}\n".format(self.X_transform.shape)
        if self.X_test_raw is not None:
            print_str += "\tX_test_raw = {}\n".format(self.X_test_raw.shape)
        if self.X_test_transform is not None:
            print_str += "\tX_test_transform = {}\n".format(self.X_test_transform.shape)
        print_str += "\tidentified classes = {}\n".format(self.classes)
        print_str += "\traw feature names = {}\n".format(self.raw_feature_names)
        print_str += "\tengineered feature names = {}\n".format(self.engineered_feature_names)
        return print_str


def _get_featurizer(fitted_model: Pipeline) -> Pipeline:
    """Return the featurizer in the AutoML model."""
    pipeline_transformer = None
    for name, transformer in fitted_model.steps[:-1]:
        if (transformer is not None) and \
                (name == Transformers.X_TRANSFORMER or name == Transformers.LAG_TRANSFORMER or
                    name == Transformers.TIMESERIES_TRANSFORMER):
            pipeline_transformer = transformer
    return pipeline_transformer


def _get_estimator(a_pipeline: Pipeline) -> Pipeline:
    """
    Return the estimator in the AutoML model.

    The estimator pipeline includes the model preprocessors and the learner.
    """
    excluded_transfomers = set([Transformers.X_TRANSFORMER, Transformers.TIMESERIES_TRANSFORMER,
                                Transformers.LAG_TRANSFORMER])
    modified_steps = [step[1] for step in a_pipeline.steps
                      if step[0] not in excluded_transfomers]
    if len(modified_steps) != len(a_pipeline.steps):
        return make_pipeline(*[s for s in modified_steps])
    else:
        return a_pipeline


def _get_feature_map(fitted_model: Pipeline, raw_feature_names_list: Optional[List[str]] = None,
                     number_of_raw_features: Optional[int] = None) -> DataInputType:
    """Generate a feature map capturing which engineered feature came from which raw feature."""
    if raw_feature_names_list is None and number_of_raw_features is None:
        raise ArgumentException.create_without_pii("At least list of raw feature names or number of raw feature" +
                                                   " are needed to generate feature map")
    if number_of_raw_features is not None:
        feature_map = np.eye(number_of_raw_features, number_of_raw_features)
        return feature_map

    transformer = _get_featurizer(fitted_model)
    if transformer is None:
        feature_map = np.eye(len(cast(List[str], raw_feature_names_list)),
                             len(cast(List[str], raw_feature_names_list)))
        return feature_map

    # Get the JSON representation of the enigneered feature names
    engineered_feature_json_str_list = transformer.get_json_strs_for_engineered_feature_names()

    # Initialize an empty feature map
    feature_map = np.zeros(shape=(len(cast(List[str], raw_feature_names_list)),
                                  len(engineered_feature_json_str_list)))

    # Create a dictionary mapping from raw feature names to indexes
    raw_feature_name_to_index_dict = \
        {cast(List[str], raw_feature_names_list)[index]: index for index in range(
            0, len(cast(List[str], raw_feature_names_list)))}

    # Iterate over all the engineered features
    for engineered_feature_index, engineered_feature_json_str in enumerate(engineered_feature_json_str_list):
        engineered_feature_json = json.loads(engineered_feature_json_str)
        transformer = engineered_feature_json['Transformations']['Transformer1']
        raw_feature_names = [n for n in transformer["Input"]]
        for raw_feature_name in raw_feature_names:
            if raw_feature_name_to_index_dict.get(raw_feature_name) is not None:
                feature_map[raw_feature_name_to_index_dict.get(raw_feature_name), engineered_feature_index] = \
                    DefaultWeightRawFeatureToEngineeredFeatureMap

    return feature_map


def _get_engineered_feature_names(fitted_model: Pipeline) -> Optional[List[str]]:
    """Get the engineered feature names from the AutoML pipeline."""
    engineered_feature_names = None
    for name, transformer in fitted_model.steps[:-1]:
        if (transformer is not None) and \
                (name == Transformers.X_TRANSFORMER or name == Transformers.LAG_TRANSFORMER or
                    name == Transformers.TIMESERIES_TRANSFORMER):
            engineered_feature_names = transformer.get_engineered_feature_names()

    return engineered_feature_names


def _convert_to_pandas_or_numpy(
        X: Optional[Union[DataInputType, TabularDataset]] = None,
        y: Optional[Union[DataSingleColumnInputType, TabularDataset]] = None,
        X_test: Optional[Union[DataInputType, TabularDataset]] = None) -> Tuple[Optional[DataInputType],
                                                                                Optional[DataSingleColumnInputType],
                                                                                Optional[DataInputType]]:
    """Convert different azureml data objects to pandas/numpy structures."""
    X_extracted = None
    X_test_extracted = None
    y_numpy = None
    comparer_obj = None
    if X is not None:
        comparer_obj = X
    elif X_test is not None:
        comparer_obj = X_test
    elif y is not None:
        comparer_obj = y
    else:
        raise ArgumentException.create_without_pii("Unable to perform any conversion")

    if isinstance(comparer_obj, pd.DataFrame) or isinstance(comparer_obj, np.ndarray) or \
            scipy.sparse.issparse(comparer_obj):
        X_extracted = X
        X_test_extracted = X_test
        y_numpy = y
    elif isinstance(comparer_obj, TabularDataset):
        if X is not None:
            X_extracted = X.to_pandas_dataframe()
        if X_test is not None:
            X_test_extracted = X_test.to_pandas_dataframe()
        if y is not None:
            y_numpy = y.to_pandas_dataframe().values
    elif dataprep_utilities.is_dataflow(comparer_obj):
        if X is not None:
            X_extracted = dataprep_utilities.retrieve_pandas_dataframe(X)

        if y is not None:
            y_numpy = dataprep_utilities.retrieve_numpy_array(y)

        if X_test is not None:
            X_test_extracted = dataprep_utilities.retrieve_pandas_dataframe(X_test)

    else:
        raise ArgumentException("Unrecognized input data format. Format detected as " + str(type(comparer_obj)))
    return X_extracted, X_test_extracted, y_numpy


def _get_transformed_data(
        fitted_model: Pipeline, X: Optional[Union[DataInputType, TabularDataset]] = None,
        y: Optional[Union[DataSingleColumnInputType, TabularDataset]] = None,
        X_test: Optional[Union[DataInputType, TabularDataset]] = None) -> Tuple[Optional[DataInputType],
                                                                                Optional[DataInputType]]:
    """
    Transform the train or test data whichever provided.

    Currently this supports only classification/regression/forecasting.
    """
    X_transform, X_test_transform, y_numpy = _convert_to_pandas_or_numpy(X=X, y=y, X_test=X_test)
    for name, transformer in fitted_model.steps[:-1]:
        if (transformer is not None) and \
                (name == Transformers.X_TRANSFORMER or name == Transformers.LAG_TRANSFORMER or
                    name == Transformers.TIMESERIES_TRANSFORMER):
            if name == Transformers.TIMESERIES_TRANSFORMER:
                if y_numpy is not None:
                    X_transform = transformer.transform(X_transform, y_numpy)
                    X_transform.pop(constants.TimeSeriesInternal.DUMMY_TARGET_COLUMN)
                    if X_test is not None:
                        X_test_transform = transformer.transform(X_test_transform)
                else:
                    raise ConfigException.create_without_pii(
                        "Explanations for timeseries requires passing of training output column")
            else:
                if X_transform is not None:
                    X_transform = transformer.transform(X_transform)
                if X_test is not None:
                    X_test_transform = transformer.transform(X_test_transform)

    X_transform = _upgrade_sparse_matrix_type(X_transform)
    X_test_transform = _upgrade_sparse_matrix_type(X_test_transform)
    return X_transform, X_test_transform


def _get_unique_classes(y: DataSingleColumnInputType) -> DataSingleColumnInputType:
    """Return the unique classes in y_train."""
    _, _, y_numpy = _convert_to_pandas_or_numpy(y=y)
    return np.unique(y_numpy)


def _get_raw_feature_names(X: DataSingleColumnInputType) -> Optional[List[str]]:
    """Extract the raw feature names from the raw data if available."""
    X_extracted, _, _ = _convert_to_pandas_or_numpy(X=X)
    if isinstance(X_extracted, pd.DataFrame):
        return list(X_extracted.columns)
    else:
        return None


def automl_setup_model_explanations(fitted_model: Pipeline, task: str,
                                    X: Optional[Union[DataInputType, TabularDataset]] = None,
                                    X_test: Optional[Union[DataInputType, TabularDataset]] = None,
                                    y: Optional[Union[DataSingleColumnInputType, TabularDataset]] = None,
                                    features: Optional[List[str]] = None,
                                    **kwargs: Any) -> AutoMLExplainerSetupClass:
    """
    Set up the featurized data for explaining an AutoML model.

    :param fitted_model: The fitted AutoML model.
    :type fitted_model: sklearn.pipeline
    :param task: 'classification', 'regression', or 'forecasting' depending on what kind of ML problem.
    :type task: str or azureml.train.automl.constants.Tasks
    :param X: The training features used when fitting pipelines during AutoML experiment.
    :type X: pandas.DataFrame or numpy.ndarray or azureml.dataprep.Dataflow or azureml.core.Dataset
        or azureml.data.dataset_definition.DatasetDefinition or azureml.data.TabularDataset
    :param y: Training labels to use when fitting pipelines during AutoML experiment.
    :type y: pandas.DataFrame or numpy.ndarray or azureml.dataprep.Dataflow or azureml.core.Dataset
        or azureml.data.dataset_definition.DatasetDefinition or azureml.data.TabularDataset
    :param X_test: Test data using which the model will be explained.
    :type X_test: pandas.DataFrame or numpy.ndarray or azureml.dataprep.Dataflow or azureml.core.Dataset
        or azureml.data.dataset_definition.DatasetDefinition or azureml.data.TabularDataset
    :param features: A list of raw feature names.
    :type features: list[str]
    :param kwargs:
    :type kwargs: dict
    :return: The model's explanation setup class
    :type: AutoMLExplainerSetupClass
    """
    if task != constants.Tasks.CLASSIFICATION and task != constants.Tasks.REGRESSION and \
            task != constants.Subtasks.FORECASTING:
        raise ArgumentException.create_without_pii('Invalid task provided')

    print("Current status: Setting up data for AutoMl explanations")
    print("Current status: Setting up the AutoML featurization for explanations")
    X_transform, X_test_transform = _get_transformed_data(fitted_model, X=X, y=y, X_test=X_test)
    _, X_test_raw, _ = _convert_to_pandas_or_numpy(X_test=X_test)
    engineered_feature_names = _get_engineered_feature_names(fitted_model)
    engineered_feature_names = features if engineered_feature_names is None else engineered_feature_names
    print("Current status: Setting up the AutoML estimator")
    estimator = _get_estimator(fitted_model)
    print("Current status: Setting up the AutoML featurizer")
    featurizer = _get_featurizer(fitted_model)
    if features is None:
        if X is not None:
            raw_feature_names = _get_raw_feature_names(X)
        elif X_test is not None:
            raw_feature_names = _get_raw_feature_names(X_test)
        else:
            raw_feature_names = None
    else:
        raw_feature_names = features
    print("Current status: Generating a feature map for raw feature importance")
    feature_map = _get_feature_map(fitted_model, raw_feature_names)
    if task == constants.Tasks.CLASSIFICATION and y is not None:
        print("Current status: Finding all classes from the dataset")
        classes = _get_unique_classes(y)
    else:
        classes = None

    print("Current status: Data for AutoMl explanations successfully setup")
    return AutoMLExplainerSetupClass(X_transform=X_transform, X_test_raw=X_test_raw,
                                     X_test_transform=X_test_transform, pipeline=fitted_model,
                                     estimator=estimator, featurizer=featurizer,
                                     engineered_feature_names=engineered_feature_names,
                                     raw_feature_names=raw_feature_names,
                                     feature_map=feature_map, classes=classes)


def _automl_perform_best_run_explain_model(parent_run: AutoMLRun, dataset: ClientDatasets,
                                           automl_settings: AutoMLBaseSettings, logger: logging.Logger,
                                           current_run: Optional[Run] = None,
                                           experiment_observer: Optional[AzureExperimentObserver] = None,
                                           console_interface: Optional[ConsoleInterface] = None) -> None:
    """
    Explain the best model in the training stage and store the explanation in that child run.

    :param parent_run: The AutoML parent run
    :type child_run: azureml.train.automl.run.AutoMLRun
    :param dataset: Containing X, y and other transformed data info
    :type dataset: ClientDatasets
    :param automl_settings: AutoML run settings
    :type automl_settings: AutoMLBaseSettings
    :param logger: logger for info/error messages.
    :param current_run: Current run for computing model explanations
    :param current_run: azureml.core.Run
    :param experiment_observer: The experiment observer.
    :type experiment_observer: azureml.train.automl._azure_experiment_observer.AzureExperimentObserver
    :param console_interface: The console interface to write the status of model explanation run.
    :type console_interface: azureml.automl.core.console_interface.ConsoleInterface
    :return: None
    """
    if automl_settings.model_explainability and parent_run.get_tags().get('model_explain_run') is not None:
        best_run, fitted_model = parent_run.get_output()
        with dataset.open_dataset():
            try:
                logger.info("Computing model explanations for best run {}".format(best_run.id))
                if current_run is not None:
                    best_run.set_tags({ModelExplanationRunId: str(current_run.id)})

                if experiment_observer is not None:
                    if console_interface is not None:
                        console_interface.print_section_separator()

                _automl_auto_mode_explain_model(best_run, dataset, automl_settings.max_cores_per_iteration,
                                                logger, pipeline=fitted_model,
                                                experiment_observer=experiment_observer)
                if experiment_observer is not None:
                    if console_interface is not None:
                        console_interface.print_section_separator()

            except Exception as e:
                logging_utilities.log_traceback(e, logger, is_critical=False)
                logger.warning(
                    "Failed model explanation for best run in fit local. Error Message: {}.".format(e)
                )
                raise e


def _automl_auto_mode_explain_model(child_run: Any,
                                    dataset: ClientDatasets,
                                    max_cores_per_iteration: int,
                                    logger: logging.Logger,
                                    pipeline: Optional[Pipeline] = None,
                                    experiment_observer: Optional[AzureExperimentObserver] = None) -> None:
    """
    Explain the model in the fit stage and store the explanation in child_run.

    :param child_run: the run to store information
    :type child_run: azureml.core.run.Run
    :param pipeline: the pipeline to explain
    :type pipeline: sklearn.pipeline.Pipeline
    :param dataset: Containing X, y and other transformed data info
    :type dataset: ClientDatasets
    :param max_cores_per_iteration: Number of cores on which surrogate model can run
    :type max_cores_per_iteration: int
    :param logger: logger for info/error messages.
    :param pipeline: AutoML fitted model
    :type pipeline: Pipeline
    :param experiment_observer: The experiment observer.
    :type experiment_observer: AzureExperimentObserver
    :return: None
    """
    from azureml.explain.model.mimic.models.lightgbm_model import LGBMExplainableModel
    from azureml.explain.model.mimic_wrapper import MimicWrapper

    if experiment_observer is not None:
        experiment_observer.report_status(ExperimentStatus.BestRunExplainModel,
                                          "Best run model explanations started")

    logger.info("[RunId:{}]Start model explanation in fit pipeline.".format(child_run.id))

    if pipeline is None:
        # Download the best model from the artifact store
        child_run.download_file(name=MODEL_PATH, output_file_path='model.pkl')
        # Load the AutoML model into memory
        pipeline = joblib.load('model.pkl')

    # Set the engineered/raw features information for model explanation
    columns = dataset.get_engineered_feature_names()
    # Convert columns from type ndarray to list
    if columns is not None and isinstance(columns, np.ndarray):
        columns = columns.tolist()

    # Set the following for MimicExplainer and LightGBM
    # 1. augment data as False
    # 2. The number of cores for LightGBM model
    explainer_kwargs = {
        'explainable_model_args': {
            'n_jobs': _get_num_physical_cpu_cores_model_explanations(max_cores_per_iteration)
        },
        'augment_data': False
    }

    logger.info("The number of core being set for explainable model is: " + str(
        _get_num_physical_cpu_cores_model_explanations(max_cores_per_iteration)))

    if experiment_observer is not None:
        experiment_observer.report_status(ExperimentStatus.ModelExplainationDataSetSetup,
                                          "Model explanations data setup started")

    # Setup the training and test samples for explanations
    X, X_valid = (dataset.get_meta('X'), dataset.get_meta('X_valid'))
    if _is_sparse_matrix_int_type(X):
        logger.info("Integer type detected for X, need to upgrade to float type")
    if _is_sparse_matrix_int_type(X_valid):
        logger.info("Integer type detected for X_valid, need to upgrade to float type")
    # If the training data is in integer format, then the data needs to reformated into float data
    # for LightGBM surrogate model. For different types of workloads, following needs to done:-
    # 1. If this is non-preprocessing/non-timeseries experiment then copy needs to be made via this
    #    conversion.
    # 2. If this is preprocessing/timeseries, then we should read from file cache and update the type
    #    in inplace. Currently we can't. TODO: Once the training data is read from the cache, then update
    #    the code below to change the type inplace.
    explainer_data_X = _upgrade_sparse_matrix_type(X)
    explainer_data_X_valid = _upgrade_sparse_matrix_type(X_valid)

    # for classification problems, get the class labels
    class_labels = dataset.get_class_labels()
    y_transformer = dataset.get_y_transformer()
    if y_transformer is not None and class_labels is not None:
        class_labels = y_transformer.inverse_transform(class_labels)

    # Prepare the feature map for raw feature importance
    if dataset.x_raw_column_names is not None:
        raw_feature_names = dataset.x_raw_column_names.tolist()
        num_raw_features = None
    else:
        raw_feature_names = None
        num_raw_features = explainer_data_X.shape[1]
    feature_map = _get_feature_map(pipeline, raw_feature_names_list=raw_feature_names,
                                   number_of_raw_features=num_raw_features)

    # To explain the pipeline which should exclude datatransformer, laggingtransformer and timeseries
    automl_estimator = _get_estimator(pipeline)

    if experiment_observer is not None:
        experiment_observer.report_status(ExperimentStatus.ModelExplainationDataSetSetup,
                                          "Model explanations data setup completed")

    logger.info("Data preparation for model explanations completed.")
    explainer = MimicWrapper(child_run.experiment.workspace, automl_estimator, LGBMExplainableModel,
                             init_dataset=explainer_data_X, run=child_run,
                             features=columns, feature_maps=[feature_map],
                             classes=class_labels, explainer_kwargs=explainer_kwargs)

    if explainer_data_X_valid is None:
        explainer_test_data = explainer_data_X
    else:
        explainer_test_data = explainer_data_X_valid

    if experiment_observer is not None:
        experiment_observer.report_status(ExperimentStatus.EngineeredFeaturesExplanations,
                                          "Computation of engineered features started")

    # Compute the engineered explanations
    explainer.explain(['local', 'global'], eval_dataset=explainer_test_data,
                      tag=AutoMLUIEngineeredFeatureExplanationName)
    logger.info("Computation of engineered feature importance completed.")

    if experiment_observer is not None:
        experiment_observer.report_status(ExperimentStatus.EngineeredFeaturesExplanations,
                                          "Computation of engineered features completed")
        experiment_observer.report_status(ExperimentStatus.RawFeaturesExplanations,
                                          "Computation of raw features started")

    # Compute the raw explanations
    explainer.explain(['local', 'global'], get_raw=True,
                      raw_feature_names=raw_feature_names,
                      eval_dataset=explainer_test_data,
                      tag=AutoMLUIRawFeatureExplanationName)
    logger.info("Computation of raw feature importance completed.")

    child_run.tag(constants.MODEL_EXPLANATION_TAG, 'True')

    logger.info("[RunId:{}]End model explanation in fit pipeline.".format(child_run.id))

    if experiment_observer is not None:
        experiment_observer.report_status(ExperimentStatus.RawFeaturesExplanations,
                                          "Computation of raw features completed")
        experiment_observer.report_status(ExperimentStatus.BestRunExplainModel,
                                          "Best run model explanations completed")
