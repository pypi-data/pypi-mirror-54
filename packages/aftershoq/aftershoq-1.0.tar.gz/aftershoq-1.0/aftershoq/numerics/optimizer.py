'''
Created on 18 Jun 2018

@author: martin
'''

import numpy as np

class Optimizer1D(object):
    '''
    classdocs
    '''


    def __init__(self, tolerance, maxiter, procmax, x0 = [], y0 = []):
        '''
        tolerance: optimization will converge after Delta x < tolerance.
        r: parameter of the optimization scheme.
        maxiter: optimization will terminate after maxiter iterations.
        procmax: maximum number of processors that can be used. This
                is the number of x-values that will be provided by the
                algorithm
        x0: Initial x-values that are already evaluated
        y0: Initial results of the evaluations at x0
        '''
        self.pmax = procmax
        self.x = []
        self.y = []
        self.tol = tolerance
        self.maxits = maxiter
        self.t = -1
        self.iter = 0
        self.converged = 0
        if(len(x0) > 0 and len(y0) > 0):
            self.addpoints(x0, y0)

    def addpoints(self,newx,newy):
        '''
        Add the newly evaluated y-values newy at the coordinates newx.
        The new results will be sorted and convergence checked.
        '''

        # Make sure each element is a scalar
        [self.x.append(np.squeeze(xx)) for xx in newx]
        [self.y.append(np.squeeze(yy)) for yy in newy]

        self.t = np.argmin(np.array(self.y))
        self.check_conv()

    def addEvaldPoints(self, model, sg, path, coords):
        '''
        Convert the evaluated points in N-dim. parameter space in the
        Sgenerator "sg", already evaluated with the Inteface
        "model", to points along the Hilbert curve and add them. "path"
        is the path to the working directory and "coords" are the
        scaled parameters generated by "sg".
        '''
        # collect results from trial points
        x0 = []
        [x0.append( sg.hutil.interp_dist_from_coords( c ) ) for c in coords]
        x0 = np.array(x0)
        x0.sort()
        x0 = x0.tolist()

        y0 = []
        xi = 0
        for i in range(0,len(x0)):
            try:
                y0.append( -float(model.getMerit(sg.structures[i],path)) )
            except( ValueError ):
                del x0[xi]
                xi-=1
            xi +=1

        y0 = np.array(y0)

        self.addpoints(x0,y0)

        return x0,y0

    def nextstep(self):
        pass

    def check_conv(self):
        '''
        Check if the minimization has converged.
        Returns:
        0 if it has not converged yet
        1 if it has converged
        -1 if it has reached the maximum allowed iterations
        '''

        if self.iter > self.maxits:
            self.converged = -1
            return
        if self.t == len(self.x)-1:
            start = self.t-2
        else:
            start = self.t-1
        for i in range(start,start+2):
            conv = abs(self.x[i]-self.x[i+1])
            if conv < self.tol:
                self.converged = 1
                return
        self.converged = 0

    def minimize(self, model, sgenerator, pathwd, pathresults = None):
        '''
        Minimizes the merit funciton by calculating next optimial structures
        to evaluate, generates them and evaluates them in each iteration.
        Returns self.converged.
        
        Parameters:
        model: The Interface in which the merit function is defined
        sgenerator: Sgenerator in which the parameter space to search is
                    defined
        pathwd: The path to the base of the working directory tree
        pathresults=None: Path to result output if needed.
        '''
        pass

    def minimize_parameters(self, model, hutil):
        pass

    def getbest(self):
        pass

class OptimizerGA(object):
    """
    Base class for genetic optimization. Inheriting classes should implement the
    below given methods.
    """

    def __init__():
        """
        Base class for genetic optimization.
        """
